{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from posenet.model import PoseNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from dataset.tartanair import TartanAirDataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\K'\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_4400\\2124055915.py:1: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  dataset = TartanAirDataset(root_dir=\"D:\\KOC UNIVERSITY\\COMP447\\data\\image_left\")\n",
      "C:\\Users\\emircan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emircan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Avg Loss = 0.008302\n",
      "Finished overfitting entire dataset.\n"
     ]
    }
   ],
   "source": [
    "dataset = TartanAirDataset(root_dir=\"D:\\KOC UNIVERSITY\\COMP447\\data\\image_left\")\n",
    "torch.cuda.empty_cache()\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "device = torch.device(\"cuda\")\n",
    "pose_net = PoseNet().to(device)\n",
    "images, translations, rotations = next(iter(train_loader))\n",
    "images = images.to(device)\n",
    "translations = translations.to(device)\n",
    "rotations = rotations.to(device)\n",
    "\n",
    "optimizer = optim.Adam(pose_net.parameters(), lr=1e-4)\n",
    "for epoch in range(1):  \n",
    "    total_epoch_loss = 0.0\n",
    "    for images, translations, rotations in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        translations = translations.to(device, non_blocking=True)\n",
    "        rotations = rotations.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t_pred, q_pred = pose_net(images)\n",
    "\n",
    "        loss = pose_net.pose_loss(t_pred, q_pred, translations, rotations)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_epoch_loss += loss.item()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}: Avg Loss = {total_epoch_loss / len(train_loader):.6f}\")\n",
    "\n",
    "print(\"Finished overfitting entire dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\K'\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_4400\\3694260985.py:6: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  img_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\image_left\"\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_4400\\3694260985.py:7: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  opt_flow_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\\\flow\"\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_4400\\3694260985.py:13: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  img_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\image_left\"\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_4400\\3694260985.py:14: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  opt_flow_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\\\flow\"\n",
      "Epoch [1/1]:   0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:   2%|▏         | 1/65 [00:01<01:40,  1.57s/it, Batch Loss=22.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:   3%|▎         | 2/65 [00:02<01:20,  1.28s/it, Batch Loss=40.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:   5%|▍         | 3/65 [00:03<01:12,  1.17s/it, Batch Loss=30.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:   6%|▌         | 4/65 [00:04<01:08,  1.13s/it, Batch Loss=58.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:   8%|▊         | 5/65 [00:05<01:06,  1.10s/it, Batch Loss=24]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:   9%|▉         | 6/65 [00:06<01:04,  1.09s/it, Batch Loss=46]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:  11%|█         | 7/65 [00:07<01:02,  1.07s/it, Batch Loss=42.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:  12%|█▏        | 8/65 [00:08<00:59,  1.05s/it, Batch Loss=30.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:  14%|█▍        | 9/65 [00:09<00:58,  1.04s/it, Batch Loss=26.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:  15%|█▌        | 10/65 [00:10<00:57,  1.04s/it, Batch Loss=33.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:  17%|█▋        | 11/65 [00:11<00:55,  1.03s/it, Batch Loss=41.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:  18%|█▊        | 12/65 [00:13<00:54,  1.03s/it, Batch Loss=36.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:  20%|██        | 13/65 [00:14<00:55,  1.06s/it, Batch Loss=35.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6, 480, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]:  20%|██        | 13/65 [00:15<01:00,  1.17s/it, Batch Loss=35.9]\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_4400\\3694260985.py:6: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  img_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\image_left\"\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_4400\\3694260985.py:7: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  opt_flow_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\\\flow\"\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_4400\\3694260985.py:13: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  img_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\image_left\"\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_4400\\3694260985.py:14: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  opt_flow_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\\\flow\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m outputs \u001b[38;5;241m=\u001b[39m nflownet(paired_batch)\n\u001b[0;32m     48\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, normal_flow_batch)\n\u001b[1;32m---> 49\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     52\u001b[0m running_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nflownet.model import NFlowNet\n",
    "from dataset.tartanair2 import PairedImageDataset\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "img_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\image_left\"\n",
    "opt_flow_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\\\flow\"\n",
    "\n",
    "dataset = PairedImageDataset(img_file_path, opt_flow_file_path)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "img_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\image_left\"\n",
    "opt_flow_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\\\flow\"\n",
    "dataset = PairedImageDataset(img_file_path, opt_flow_file_path)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "test_size = len(dataset) - train_size  # Remaining 20% for testing\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "nflownet = NFlowNet().to(device)\n",
    "optimizer = torch.optim.Adam(nflownet.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    nflownet.train()\n",
    "    running_train_loss = 0.0\n",
    "    batch_losses = []\n",
    "\n",
    "    # Wrap train_loader with tqdm\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "\n",
    "    for paired_batch, normal_flow_batch in pbar:\n",
    "        paired_batch, normal_flow_batch = paired_batch.to(device), normal_flow_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        print(paired_batch.size())\n",
    "        outputs = nflownet(paired_batch)\n",
    "\n",
    "        loss = criterion(outputs, normal_flow_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        # Update progress bar with current batch loss\n",
    "        pbar.set_postfix({'Batch Loss': loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CheiralityLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Differentiable Cheirality Layer that enforces depth positivity constraint\n",
    "    using normal flow estimates from NFlowNet.\n",
    "    \n",
    "    Args:\n",
    "        max_iter (int): Maximum iterations for optimization\n",
    "        tol (float): Tolerance for convergence\n",
    "        lr (float): Learning rate for L-BFGS optimizer\n",
    "    \"\"\"\n",
    "    def __init__(self, max_iter=100, tol=1e-20, lr=0.1):\n",
    "        super(CheiralityLayer, self).__init__()\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.lr = lr\n",
    "        \n",
    "    def forward(self, normal_flow, image_gradients, init_pose):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            normal_flow (torch.Tensor): Estimated normal flow from NFlowNet [B, H, W]\n",
    "            image_gradients (torch.Tensor): Image spatial gradients [B, 2, H, W]\n",
    "            init_pose (torch.Tensor): Initial pose estimate from PoseNet [B, 6] (3 translation, 3 rotation)\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Refined pose estimate [B, 6]\n",
    "        \"\"\"\n",
    "        batch_size = init_pose.size(0)\n",
    "        refined_poses = []\n",
    "        \n",
    "        # Process each sample in batch separately\n",
    "        for i in range(batch_size):\n",
    "            nf = normal_flow[i]  # [H, W]\n",
    "            grad = image_gradients[i]  # [2, H, W]\n",
    "            init_p = init_pose[i]  # [6]\n",
    "            \n",
    "            # Convert to numpy for L-BFGS (paper uses this approach)\n",
    "            # Note: In practice you might want to keep everything in PyTorch\n",
    "            refined_p = self.optimize_pose(nf, grad, init_p)\n",
    "            refined_poses.append(refined_p)\n",
    "            \n",
    "        return torch.stack(refined_poses, dim=0)\n",
    "    \n",
    "    def optimize_pose(self, normal_flow, image_gradients, init_pose):\n",
    "        \"\"\"\n",
    "        Optimize pose using cheirality constraint with L-BFGS\n",
    "        \n",
    "        Args:\n",
    "            normal_flow (torch.Tensor): [H, W]\n",
    "            image_gradients (torch.Tensor): [2, H, W]\n",
    "            init_pose (torch.Tensor): [6]\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Refined pose [6]\n",
    "        \"\"\"\n",
    "        # Convert to numpy for optimization (as done in paper)\n",
    "        # Alternatively could implement fully in PyTorch using torch.optim.LBFGS\n",
    "        import numpy as np\n",
    "        from scipy.optimize import minimize\n",
    "        \n",
    "        # Normalize gradients to get direction (unit vectors)\n",
    "        grad_norm = torch.norm(image_gradients, dim=0, keepdim=True)\n",
    "        grad_dir = image_gradients / (grad_norm + 1e-6)  # [2, H, W]\n",
    "        \n",
    "        # Get image coordinates grid\n",
    "        _, H, W = normal_flow.shape\n",
    "        y_coords, x_coords = torch.meshgrid(torch.arange(H), torch.arange(W))\n",
    "        coords = torch.stack([x_coords, y_coords], dim=0).float().to(normal_flow.device)  # [2, H, W]\n",
    "        \n",
    "        # Prepare data for optimization\n",
    "        nf_np = normal_flow.detach().cpu().numpy().flatten()\n",
    "        grad_dir_np = grad_dir.detach().cpu().numpy().reshape(2, -1)  # [2, H*W]\n",
    "        coords_np = coords.detach().cpu().numpy().reshape(2, -1)  # [2, H*W]\n",
    "        init_pose_np = init_pose.detach().cpu().numpy()\n",
    "        \n",
    "        # Define objective function\n",
    "        def objective(pose_params):\n",
    "            V = pose_params[:3]  # translation\n",
    "            Omega = pose_params[3:]  # rotation\n",
    "            \n",
    "            # Compute A and B matrices (from paper equations 9-10)\n",
    "            x, y = coords_np\n",
    "            ones = np.ones_like(x)\n",
    "            zeros = np.zeros_like(x)\n",
    "            \n",
    "            # A matrix [2, 3] -> [H*W, 2, 3]\n",
    "            A = np.stack([\n",
    "                -ones, zeros, x,\n",
    "                zeros, -ones, y\n",
    "            ], axis=1).reshape(-1, 2, 3)\n",
    "            \n",
    "            # B matrix [2, 3] -> [H*W, 2, 3]\n",
    "            B = np.stack([\n",
    "                x*y, -(x**2 + 1), y,\n",
    "                (y**2 + 1), -x*y, -x\n",
    "            ], axis=1).reshape(-1, 2, 3)\n",
    "            \n",
    "            # Compute rho (equation 12)\n",
    "            g_dot_A = np.einsum('hwi,hwi->hw', grad_dir_np.T[:, None, :], A)  # [H*W, 3]\n",
    "            g_dot_B = np.einsum('hwi,hwi->hw', grad_dir_np.T[:, None, :], B)  # [H*W, 3]\n",
    "            \n",
    "            term1 = np.dot(g_dot_A, V)  # [H*W]\n",
    "            term2 = nf_np - np.dot(g_dot_B, Omega)  # [H*W]\n",
    "            \n",
    "            rho = term1 * term2  # [H*W]\n",
    "            \n",
    "            # GELU activation (smooth ReLU approximation)\n",
    "            # Negative GELU as in paper equation 13\n",
    "            loss = -0.5 * rho * (1.0 + torch.erf(rho / np.sqrt(2.0)))  # GELU approximation\n",
    "            return np.mean(loss)\n",
    "        \n",
    "        # Run L-BFGS optimization\n",
    "        result = minimize(objective, \n",
    "                         init_pose_np,\n",
    "                         method='L-BFGS-B',\n",
    "                         options={'maxiter': self.max_iter,\n",
    "                                'ftol': self.tol,\n",
    "                                'gtol': self.tol})\n",
    "        \n",
    "        refined_pose = torch.from_numpy(result.x).float().to(init_pose.device)\n",
    "        return refined_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class DiffPoseNet(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Complete DiffPoseNet framework integrating:\n",
    "    - NFlowNet for normal flow estimation\n",
    "    - PoseNet for initial pose estimation\n",
    "    - CheiralityLayer for pose refinement\n",
    "    \"\"\"\n",
    "    def __init__(self, nflownet, posenet, cheirality_layer):\n",
    "        super(DiffPoseNet, self).__init__()\n",
    "        self.nflownet = nflownet\n",
    "        self.posenet = posenet\n",
    "        self.cheirality_layer = cheirality_layer\n",
    "        \n",
    "    def forward(self, img1, img2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img1 (torch.Tensor): First image [B, C, H, W]\n",
    "            img2 (torch.Tensor): Second image [B, C, H, W]\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (refined_pose, init_pose, normal_flow)\n",
    "        \"\"\"\n",
    "        resize_transform = transforms.Compose([\n",
    "            transforms.Resize((480, 640))  # (height, width)\n",
    "            ])\n",
    "        img1_resized = resize_transform(img1)\n",
    "        img2_resized = resize_transform(img2)\n",
    "        # Compute normal flow between images\n",
    "        with torch.no_grad():\n",
    "            img = torch.cat((img1_resized, img2_resized), dim=1)\n",
    "            normal_flow = self.nflownet(img)  # [B, H, W]\n",
    "        \n",
    "        # Compute image gradients (for cheirality layer)\n",
    "        # Using Sobel filters as approximation\n",
    "        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32, device=img1.device).view(1, 1, 3, 3)\n",
    "        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32, device=img1.device).view(1, 1, 3, 3)\n",
    "        \n",
    "        # Compute gradients for both images and average\n",
    "        grad_x1 = F.conv2d(img1.mean(dim=1, keepdim=True), sobel_x, padding=1)\n",
    "        grad_y1 = F.conv2d(img1.mean(dim=1, keepdim=True), sobel_y, padding=1)\n",
    "        grad_x2 = F.conv2d(img2.mean(dim=1, keepdim=True), sobel_x, padding=1)\n",
    "        grad_y2 = F.conv2d(img2.mean(dim=1, keepdim=True), sobel_y, padding=1)\n",
    "        \n",
    "        image_gradients = 0.5 * (torch.cat([grad_x1, grad_y1], dim=1) + torch.cat([grad_x2, grad_y2], dim=1))  # [B, 2, H, W]\n",
    "        \n",
    "        # Get initial pose estimate\n",
    "        init_pose = self.posenet(torch.stack([img1, img2], dim=1))  # [B, 6]\n",
    "        t_pred, q_pred = self.posenet(torch.stack([img1, img2], dim=1))\n",
    "        init_pose = torch.cat([t_pred, q_pred], dim=1)  # [B, 7]\n",
    "        # Refine pose using cheirality layer\n",
    "        refined_pose = self.cheirality_layer(normal_flow, image_gradients, init_pose)\n",
    "        \n",
    "        return refined_pose, init_pose, normal_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (50176,2)->(50176,newaxis,2) (307200,2,3)->(307200,3,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Forward pass through DiffPoseNet\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m refined_pose, init_pose, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdiffposenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Calculate loss between refined pose and ground truth\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Assuming refined_pose contains both translation and rotation\u001b[39;00m\n\u001b[0;32m     37\u001b[0m t_pred \u001b[38;5;241m=\u001b[39m refined_pose[:, :\u001b[38;5;241m3\u001b[39m]  \u001b[38;5;66;03m# Predicted translation\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[51], line 57\u001b[0m, in \u001b[0;36mDiffPoseNet.forward\u001b[1;34m(self, img1, img2)\u001b[0m\n\u001b[0;32m     55\u001b[0m init_pose \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([t_pred, q_pred], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [B, 7]\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Refine pose using cheirality layer\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m refined_pose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheirality_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_flow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_pose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m refined_pose, init_pose, normal_flow\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[53], line 41\u001b[0m, in \u001b[0;36mCheiralityLayer.forward\u001b[1;34m(self, normal_flow, image_gradients, init_pose)\u001b[0m\n\u001b[0;32m     37\u001b[0m     init_p \u001b[38;5;241m=\u001b[39m init_pose[i]  \u001b[38;5;66;03m# [6]\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Convert to numpy for L-BFGS (paper uses this approach)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Note: In practice you might want to keep everything in PyTorch\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     refined_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_pose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     refined_poses\u001b[38;5;241m.\u001b[39mappend(refined_p)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(refined_poses, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[53], line 115\u001b[0m, in \u001b[0;36mCheiralityLayer.optimize_pose\u001b[1;34m(self, normal_flow, image_gradients, init_pose)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(loss)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Run L-BFGS optimization\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m                 \u001b[49m\u001b[43minit_pose_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m refined_pose \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(result\u001b[38;5;241m.\u001b[39mx)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(init_pose\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m refined_pose\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:347\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    344\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# _prepare_scalar_function can use bounds=None to represent no bounds\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[0;32m    353\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_optimize.py:288\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    284\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:166\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[1;32mIn[53], line 101\u001b[0m, in \u001b[0;36mCheiralityLayer.optimize_pose.<locals>.objective\u001b[1;34m(pose_params)\u001b[0m\n\u001b[0;32m     95\u001b[0m B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\n\u001b[0;32m     96\u001b[0m     x\u001b[38;5;241m*\u001b[39my, \u001b[38;5;241m-\u001b[39m(x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), y,\n\u001b[0;32m     97\u001b[0m     (y\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m-\u001b[39mx\u001b[38;5;241m*\u001b[39my, \u001b[38;5;241m-\u001b[39mx\n\u001b[0;32m     98\u001b[0m ], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Compute rho (equation 12)\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m g_dot_A \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhi,hij->hj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_dir_np\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [H*W, 3]\u001b[39;00m\n\u001b[0;32m    102\u001b[0m g_dot_B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhi,hij->hj\u001b[39m\u001b[38;5;124m'\u001b[39m, grad_dir_np\u001b[38;5;241m.\u001b[39mT, B)  \u001b[38;5;66;03m# [H*W, 3]\u001b[39;00m\n\u001b[0;32m    104\u001b[0m term1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(g_dot_A, V)  \u001b[38;5;66;03m# [H*W]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\core\\einsumfunc.py:1371\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[0;32m   1370\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m-> 1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m valid_einsum_kwargs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (50176,2)->(50176,newaxis,2) (307200,2,3)->(307200,3,2) "
     ]
    }
   ],
   "source": [
    "nflownet.eval()  # We won't train the flow networks\n",
    "\n",
    "cheirality_layer = CheiralityLayer().to(device)\n",
    "\n",
    "# Create DiffPoseNet framework\n",
    "diffposenet = DiffPoseNet(nflownet, pose_net, cheirality_layer).to(device)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = TartanAirDataset(root_dir=\"D:/KOC UNIVERSITY/COMP447/data/image_left\")\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Optimizer (only for PoseNet parameters)\n",
    "optimizer = optim.Adam(pose_net.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    pose_net.train()  # Only train PoseNet\n",
    "    \n",
    "    for batch_idx, (images, translations, rotations) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        translations = translations.to(device)\n",
    "        rotations = rotations.to(device)\n",
    "        \n",
    "        # Split images into pairs (assuming consecutive frames)\n",
    "        img1 = images[:, 0]  # First image in pair\n",
    "        img2 = images[:, 1]  # Second image in pair\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass through DiffPoseNet\n",
    "        refined_pose, init_pose, _ = diffposenet(img1, img2)\n",
    "        \n",
    "        # Calculate loss between refined pose and ground truth\n",
    "        # Assuming refined_pose contains both translation and rotation\n",
    "        t_pred = refined_pose[:, :3]  # Predicted translation\n",
    "        q_pred = refined_pose[:, 3:]  # Predicted rotation (quaternion)\n",
    "        \n",
    "        # Use PoseNet's loss function\n",
    "        loss = pose_net.pose_loss(t_pred, q_pred, translations, rotations)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}: Loss = {loss.item():.6f}\")\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch} completed. Average Loss: {avg_loss:.6f}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
