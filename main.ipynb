{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from posenet.model import PoseNetDino\n",
    "from nflownet.model import NFlowNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from dataset.tartanair import TartanAirDataset\n",
    "import random\n",
    "import numpy as np\n",
    "from cheirality.cheiralityLayer import CheiralityLayer\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "def load_posenet(posenet_path):\n",
    "    # Initialize PoseNet model\n",
    "    posenet = PoseNetDino().to(device)\n",
    "    \n",
    "    # Load weights from .safetensors file\n",
    "    with safe_open(posenet_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        state_dict = {}\n",
    "        for key in f.keys():\n",
    "            state_dict[key] = f.get_tensor(key)\n",
    "    \n",
    "    # Load state dict into model\n",
    "    posenet.load_state_dict(state_dict)\n",
    "    posenet.train()\n",
    "    \n",
    "    return posenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nflownet(nflownet_path):\n",
    "    # Initialize FlowNet model\n",
    "    nflownet = NFlowNet().to(device)\n",
    "    \n",
    "    # Load weights from .pth file\n",
    "    checkpoint = torch.load(nflownet_path, map_location=device)\n",
    "    \n",
    "    # Handle different save formats\n",
    "    if 'state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    elif 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    # Load state dict into model\n",
    "    nflownet.load_state_dict(state_dict)\n",
    "    nflownet.eval()  # Set to evaluation mode\n",
    "    \n",
    "    return nflownet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\emircan/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "C:\\Users\\emircan/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "C:\\Users\\emircan/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "C:\\Users\\emircan/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PoseNetDino:\n\tMissing key(s) in state_dict: \"lstm.weight_hh_l0\", \"lstm.bias_ih_l0\", \"lstm.bias_hh_l0\", \"lstm.weight_ih_l1\", \"lstm.weight_hh_l1\", \"lstm.bias_ih_l1\", \"lstm.bias_hh_l1\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m posenet_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mKOC UNIVERSITY\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCOMP447\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrainedmodels\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mposenet\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodel.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m nflownet_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mKOC UNIVERSITY\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCOMP447\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrainedmodels\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnflownet\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnflownet_final.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m posenet \u001b[38;5;241m=\u001b[39m \u001b[43mload_posenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposenet_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m nflownet \u001b[38;5;241m=\u001b[39m load_nflownet(nflownet_path)\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mload_posenet\u001b[1;34m(posenet_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m         state_dict[key] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mget_tensor(key)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Load state dict into model\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mposenet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m posenet\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m posenet\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2580\u001b[0m             ),\n\u001b[0;32m   2581\u001b[0m         )\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2587\u001b[0m         )\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PoseNetDino:\n\tMissing key(s) in state_dict: \"lstm.weight_hh_l0\", \"lstm.bias_ih_l0\", \"lstm.bias_hh_l0\", \"lstm.weight_ih_l1\", \"lstm.weight_hh_l1\", \"lstm.bias_ih_l1\", \"lstm.bias_hh_l1\". "
     ]
    }
   ],
   "source": [
    "posenet_path = r\"D:\\KOC UNIVERSITY\\COMP447\\trainedmodels\\posenet\\model.safetensors\"\n",
    "nflownet_path = r\"D:\\KOC UNIVERSITY\\COMP447\\trainedmodels\\nflownet\\nflownet_final.pth\"\n",
    "\n",
    "posenet = load_posenet(posenet_path)\n",
    "nflownet = load_nflownet(nflownet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheirality_layer = CheiralityLayer(nflownet=nflownet,posenet=posenet).to(device)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = TartanAirDataset(root_dir=\"D:/KOC UNIVERSITY/COMP447/data/image_left\")\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Optimizer (only for PoseNet parameters)\n",
    "optimizer = optim.Adam(posenet.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for images, _, _ in train_loader:\n",
    "        loss = cheirality_layer(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss / len(train_loader)}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
