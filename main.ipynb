{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from posenet.model import PoseNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from dataset.tartanair import TartanAirDataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\K'\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_12312\\2124055915.py:1: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  dataset = TartanAirDataset(root_dir=\"D:\\KOC UNIVERSITY\\COMP447\\data\\image_left\")\n",
      "C:\\Users\\emircan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emircan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Avg Loss = 0.005748\n",
      "Finished overfitting entire dataset.\n"
     ]
    }
   ],
   "source": [
    "dataset = TartanAirDataset(root_dir=\"D:\\KOC UNIVERSITY\\COMP447\\data\\image_left\")\n",
    "torch.cuda.empty_cache()\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "device = torch.device(\"cuda\")\n",
    "pose_net = PoseNet().to(device)\n",
    "images, translations, rotations = next(iter(train_loader))\n",
    "images = images.to(device)\n",
    "translations = translations.to(device)\n",
    "rotations = rotations.to(device)\n",
    "\n",
    "optimizer = optim.Adam(pose_net.parameters(), lr=1e-4)\n",
    "for epoch in range(1):  \n",
    "    total_epoch_loss = 0.0\n",
    "    for images, translations, rotations in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        translations = translations.to(device, non_blocking=True)\n",
    "        rotations = rotations.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t_pred, q_pred = pose_net(images)\n",
    "\n",
    "        loss = pose_net.pose_loss(t_pred, q_pred, translations, rotations)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_epoch_loss += loss.item()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}: Avg Loss = {total_epoch_loss / len(train_loader):.6f}\")\n",
    "\n",
    "print(\"Finished overfitting entire dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\K'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\K'\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_12312\\3440722129.py:6: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  img_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\image_left\"\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_12312\\3440722129.py:7: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  opt_flow_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\\\flow\"\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_12312\\3440722129.py:13: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  img_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\image_left\"\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_12312\\3440722129.py:14: SyntaxWarning: invalid escape sequence '\\K'\n",
      "  opt_flow_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\\\flow\"\n",
      "Epoch [1/1]: 100%|██████████| 65/65 [00:54<00:00,  1.18it/s, Batch Loss=22.7]\n"
     ]
    }
   ],
   "source": [
    "from nflownet.model import NFlowNet\n",
    "from dataset.tartanair2 import PairedImageDataset\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "img_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\image_left\"\n",
    "opt_flow_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\\\flow\"\n",
    "\n",
    "dataset = PairedImageDataset(img_file_path, opt_flow_file_path)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "img_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\image_left\"\n",
    "opt_flow_file_path = \"D:\\KOC UNIVERSITY\\COMP447\\\\amusement_sample_P008\\P008\\\\flow\"\n",
    "dataset = PairedImageDataset(img_file_path, opt_flow_file_path)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "test_size = len(dataset) - train_size  # Remaining 20% for testing\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "nflownet = NFlowNet().to(device)\n",
    "optimizer = torch.optim.Adam(nflownet.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    nflownet.train()\n",
    "    running_train_loss = 0.0\n",
    "    batch_losses = []\n",
    "\n",
    "    # Wrap train_loader with tqdm\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "\n",
    "    for paired_batch, normal_flow_batch in pbar:\n",
    "        paired_batch, normal_flow_batch = paired_batch.to(device), normal_flow_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = nflownet(paired_batch)\n",
    "\n",
    "        loss = criterion(outputs, normal_flow_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        # Update progress bar with current batch loss\n",
    "        pbar.set_postfix({'Batch Loss': loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CheiralityLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Differentiable Cheirality Layer that enforces depth positivity constraint\n",
    "    using normal flow estimates from NFlowNet.\n",
    "    \n",
    "    Args:\n",
    "        max_iter (int): Maximum iterations for optimization\n",
    "        tol (float): Tolerance for convergence\n",
    "        lr (float): Learning rate for L-BFGS optimizer\n",
    "    \"\"\"\n",
    "    def __init__(self, max_iter=100, tol=1e-20, lr=0.1):\n",
    "        super(CheiralityLayer, self).__init__()\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.lr = lr\n",
    "        \n",
    "    def forward(self, normal_flow, image_gradients, init_pose):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            normal_flow (torch.Tensor): Estimated normal flow from NFlowNet [B, H, W]\n",
    "            image_gradients (torch.Tensor): Image spatial gradients [B, 2, H, W]\n",
    "            init_pose (torch.Tensor): Initial pose estimate from PoseNet [B, 6] (3 translation, 3 rotation)\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Refined pose estimate [B, 6]\n",
    "        \"\"\"\n",
    "        batch_size = init_pose.size(0)\n",
    "        refined_poses = []\n",
    "        \n",
    "        # Process each sample in batch separately\n",
    "        for i in range(batch_size):\n",
    "            nf = normal_flow[i]  # [H, W]\n",
    "            grad = image_gradients[i]  # [2, H, W]\n",
    "            init_p = init_pose[i]  # [6]\n",
    "            \n",
    "            # Convert to numpy for L-BFGS (paper uses this approach)\n",
    "            # Note: In practice you might want to keep everything in PyTorch\n",
    "            refined_p = self.optimize_pose(nf, grad, init_p)\n",
    "            refined_poses.append(refined_p)\n",
    "            \n",
    "        return torch.stack(refined_poses, dim=0)\n",
    "    \n",
    "    def optimize_pose(self, normal_flow, image_gradients, init_pose):\n",
    "        \"\"\"\n",
    "        Optimize pose using cheirality constraint with L-BFGS\n",
    "        \n",
    "        Args:\n",
    "            normal_flow (torch.Tensor): [H, W]\n",
    "            image_gradients (torch.Tensor): [2, H, W]\n",
    "            init_pose (torch.Tensor): [6]\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Refined pose [6]\n",
    "        \"\"\"\n",
    "        # Convert to numpy for optimization (as done in paper)\n",
    "        # Alternatively could implement fully in PyTorch using torch.optim.LBFGS\n",
    "        import numpy as np\n",
    "        from scipy.optimize import minimize\n",
    "        \n",
    "        # Normalize gradients to get direction (unit vectors)\n",
    "        grad_norm = torch.norm(image_gradients, dim=0, keepdim=True)\n",
    "        grad_dir = image_gradients / (grad_norm + 1e-6)  # [2, H, W]\n",
    "        \n",
    "        # Get image coordinates grid\n",
    "        _, H, W = normal_flow.shape\n",
    "        magnitude = torch.sqrt(normal_flow[0]**2 + normal_flow[1]**2)\n",
    "        y_coords, x_coords = torch.meshgrid(torch.arange(H), torch.arange(W))\n",
    "        coords = torch.stack([x_coords, y_coords], dim=0).float().to(normal_flow.device)  # [2, H, W]\n",
    "        \n",
    "        # Prepare data for optimization\n",
    "        nf_np = magnitude.detach().cpu().numpy().flatten()\n",
    "        grad_dir_np = grad_dir.detach().cpu().numpy().reshape(2, -1)  # [2, H*W]\n",
    "        coords_np = coords.detach().cpu().numpy().reshape(2, -1)  # [2, H*W]\n",
    "        init_pose_np = init_pose.detach().cpu().numpy()\n",
    "        \n",
    "        # Define objective function\n",
    "        def objective(pose_params):\n",
    "            V = pose_params[:3]  # translation\n",
    "            Omega = pose_params[3:]  # rotation\n",
    "            \n",
    "            # Compute A and B matrices (from paper equations 9-10)\n",
    "            x, y = coords_np\n",
    "            ones = np.ones_like(x)\n",
    "            zeros = np.zeros_like(x)\n",
    "            \n",
    "            # A matrix [2, 3] -> [H*W, 2, 3]\n",
    "            A = np.stack([\n",
    "                -ones, zeros, x,\n",
    "                zeros, -ones, y\n",
    "            ], axis=1).reshape(-1, 2, 3)\n",
    "            \n",
    "            # B matrix [2, 3] -> [H*W, 2, 3]\n",
    "            B = np.stack([\n",
    "                x*y, -(x**2 + 1), y,\n",
    "                (y**2 + 1), -x*y, -x\n",
    "            ], axis=1).reshape(-1, 2, 3)\n",
    "\n",
    "            \n",
    "            g_dot_A = np.matmul(grad_dir_np.T[:, np.newaxis, :], A).squeeze(1)  # [H*W, 3]\n",
    "            g_dot_B = np.matmul(grad_dir_np.T[:, np.newaxis, :], B).squeeze(1)\n",
    "            term1 = np.dot(g_dot_A, V)  # [H*W]\n",
    "            term2 = nf_np - np.dot(g_dot_B, Omega)  # [H*W]\n",
    "            \n",
    "            rho = term1 * term2  # [H*W]\n",
    "            \n",
    "            # GELU activation (smooth ReLU approximation)\n",
    "            # Negative GELU as in paper equation 13\n",
    "            from scipy.special import erf\n",
    "            loss = -0.5 * rho * (1.0 + erf(rho / np.sqrt(2.0)))  # GELU approximation\n",
    "            return np.mean(loss)\n",
    "        \n",
    "        # Run L-BFGS optimization\n",
    "        result = minimize(objective, \n",
    "                         init_pose_np,\n",
    "                         method='L-BFGS-B',\n",
    "                         options={'maxiter': self.max_iter,\n",
    "                                'ftol': self.tol,\n",
    "                                'gtol': self.tol})\n",
    "        \n",
    "        refined_pose = torch.from_numpy(result.x).float().to(init_pose.device)\n",
    "        return refined_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def quaternion_to_euler_xyz(q: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts a quaternion to Euler angles (X-Y-Z order: roll-pitch-yaw)\n",
    "    \n",
    "    Args:\n",
    "        q: [B, 4] tensor in [x, y, z, w] format.\n",
    "\n",
    "    Returns:\n",
    "        euler_angles: [B, 3] tensor with angles in radians: [roll(X), pitch(Y), yaw(Z)]\n",
    "    \"\"\"\n",
    "    x, y, z, w = q[:, 0], q[:, 1], q[:, 2], q[:, 3]\n",
    "\n",
    "    # Compute rotation matrix elements\n",
    "    t0 = 2.0 * (w * x + y * z)\n",
    "    t1 = 1.0 - 2.0 * (x * x + y * y)\n",
    "    roll_x = torch.atan2(t0, t1)\n",
    "\n",
    "    t2 = 2.0 * (w * y - z * x)\n",
    "    t2 = torch.clamp(t2, -1.0, 1.0)\n",
    "    pitch_y = torch.asin(t2)\n",
    "\n",
    "    t3 = 2.0 * (w * z + x * y)\n",
    "    t4 = 1.0 - 2.0 * (y * y + z * z)\n",
    "    yaw_z = torch.atan2(t3, t4)\n",
    "\n",
    "    euler_angles = torch.stack([roll_x, pitch_y, yaw_z], dim=1)  # [B, 3]\n",
    "    return euler_angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def euler_xyz_to_quaternion(euler: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts Euler angles (X-Y-Z order: roll-pitch-yaw) to quaternion.\n",
    "\n",
    "    Args:\n",
    "        euler: [B, 3] tensor with angles in radians: [roll(X), pitch(Y), yaw(Z)]\n",
    "\n",
    "    Returns:\n",
    "        q: [B, 4] tensor in [x, y, z, w] format.\n",
    "    \"\"\"\n",
    "    roll, pitch, yaw = euler[:, 0], euler[:, 1], euler[:, 2]\n",
    "\n",
    "    cr = torch.cos(roll * 0.5)\n",
    "    sr = torch.sin(roll * 0.5)\n",
    "    cp = torch.cos(pitch * 0.5)\n",
    "    sp = torch.sin(pitch * 0.5)\n",
    "    cy = torch.cos(yaw * 0.5)\n",
    "    sy = torch.sin(yaw * 0.5)\n",
    "\n",
    "    w = cr * cp * cy + sr * sp * sy\n",
    "    x = sr * cp * cy - cr * sp * sy\n",
    "    y = cr * sp * cy + sr * cp * sy\n",
    "    z = cr * cp * sy - sr * sp * cy\n",
    "\n",
    "    q = torch.stack([x, y, z, w], dim=1)  # [B, 4]\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class DiffPoseNet(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Complete DiffPoseNet framework integrating:\n",
    "    - NFlowNet for normal flow estimation\n",
    "    - PoseNet for initial pose estimation\n",
    "    - CheiralityLayer for pose refinement\n",
    "    \"\"\"\n",
    "    def __init__(self, nflownet, posenet, cheirality_layer):\n",
    "        super(DiffPoseNet, self).__init__()\n",
    "        self.nflownet = nflownet\n",
    "        self.posenet = posenet\n",
    "        self.cheirality_layer = cheirality_layer\n",
    "        \n",
    "    def forward(self, img1, img2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img1 (torch.Tensor): First image [B, C, H, W]\n",
    "            img2 (torch.Tensor): Second image [B, C, H, W]\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (refined_pose, init_pose, normal_flow)\n",
    "        \"\"\"\n",
    "        resize_transform = transforms.Compose([\n",
    "            transforms.Resize((480, 640))  # (height, width)\n",
    "            ])\n",
    "        img1_resized = resize_transform(img1)\n",
    "        img2_resized = resize_transform(img2)\n",
    "        # Compute normal flow between images\n",
    "        with torch.no_grad():\n",
    "            img = torch.cat((img1_resized, img2_resized), dim=1)\n",
    "            normal_flow = self.nflownet(img)  # [B, H, W]\n",
    "        \n",
    "        # Compute image gradients (for cheirality layer)\n",
    "        # Using Sobel filters as approximation\n",
    "        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32, device=img1.device).view(1, 1, 3, 3)\n",
    "        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32, device=img1.device).view(1, 1, 3, 3)\n",
    "        \n",
    "        # Compute gradients for both images and average\n",
    "        grad_x1 = F.conv2d(img1_resized.mean(dim=1, keepdim=True), sobel_x, padding=1)\n",
    "        grad_y1 = F.conv2d(img1_resized.mean(dim=1, keepdim=True), sobel_y, padding=1)\n",
    "        grad_x2 = F.conv2d(img2_resized.mean(dim=1, keepdim=True), sobel_x, padding=1)\n",
    "        grad_y2 = F.conv2d(img2_resized.mean(dim=1, keepdim=True), sobel_y, padding=1)\n",
    "        \n",
    "        image_gradients = 0.5 * (torch.cat([grad_x1, grad_y1], dim=1) + torch.cat([grad_x2, grad_y2], dim=1))  # [B, 2, H, W]\n",
    "        \n",
    "        # Get initial pose estimate\n",
    "        t_pred, q_pred = self.posenet(torch.stack([img1, img2], dim=1))\n",
    "        r_pred = quaternion_to_euler_xyz(q_pred)\n",
    "        init_pose = torch.cat([t_pred, r_pred], dim=1)  # [B, 6]\n",
    "        # Refine pose using cheirality layer\n",
    "        refined_pose = self.cheirality_layer(normal_flow, image_gradients, init_pose)\n",
    "        \n",
    "        return refined_pose, init_pose, normal_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0490, -0.0569,  0.3437]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0490, -0.0569,  0.3437]], device='cuda:0')\n",
      "tensor([[-0.2551,  0.5312, -0.6528,  0.4760]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[-0.2551,  0.5312, -0.6528,  0.4760]], device='cuda:0')\n",
      "Loss is calculated: 0.0\n",
      "Epoch 0, Batch 0: Loss = 0.000000\n",
      "tensor([[-0.0063, -0.0573,  0.3954]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0063, -0.0573,  0.3954]], device='cuda:0')\n",
      "tensor([[-0.1010,  0.6814, -0.6568,  0.3068]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[-0.1010,  0.6814, -0.6568,  0.3068]], device='cuda:0')\n",
      "Loss is calculated: 0.0\n",
      "tensor([[ 0.0143, -0.0961,  0.1984]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.0143, -0.0961,  0.1984]], device='cuda:0')\n",
      "tensor([[-0.2131,  0.5060, -0.7341,  0.3996]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[-0.2131,  0.5060, -0.7341,  0.3996]], device='cuda:0')\n",
      "Loss is calculated: 0.0\n",
      "tensor([[-0.0276, -0.0563,  0.3470]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0276, -0.0563,  0.3470]], device='cuda:0')\n",
      "tensor([[-0.1412,  0.6905, -0.6591,  0.2623]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[-0.1412,  0.6905, -0.6591,  0.2623]], device='cuda:0')\n",
      "Loss is calculated: 0.0\n",
      "tensor([[ 0.0068, -0.0842,  0.3946]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.0068, -0.0842,  0.3946]], device='cuda:0')\n",
      "tensor([[-0.0616,  0.7141, -0.6631,  0.2155]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[-0.0616,  0.7141, -0.6631,  0.2155]], device='cuda:0')\n",
      "Loss is calculated: 0.0\n",
      "tensor([[-0.0561, -0.0903,  0.3411]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0561, -0.0903,  0.3411]], device='cuda:0')\n",
      "tensor([[-0.1468,  0.5920, -0.7368,  0.2915]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[-0.1468,  0.5920, -0.7368,  0.2915]], device='cuda:0')\n",
      "Loss is calculated: 0.0\n",
      "tensor([[-0.0094, -0.1476,  0.3521]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0094, -0.1476,  0.3521]], device='cuda:0')\n",
      "tensor([[ 0.0018,  0.5527, -0.7682,  0.3231]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.0018,  0.5527, -0.7682,  0.3231]], device='cuda:0')\n",
      "Loss is calculated: 0.0\n",
      "tensor([[-0.0144, -0.1140,  0.3415]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0144, -0.1140,  0.3415]], device='cuda:0')\n",
      "tensor([[-0.0059,  0.4974, -0.8248,  0.2687]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[-0.0059,  0.4974, -0.8248,  0.2687]], device='cuda:0')\n",
      "Loss is calculated: 0.0\n",
      "tensor([[ 0.0333, -0.1049,  0.3254]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.0333, -0.1049,  0.3254]], device='cuda:0')\n",
      "tensor([[-0.1771,  0.5837, -0.7577,  0.2321]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[-0.1771,  0.5837, -0.7577,  0.2321]], device='cuda:0')\n",
      "Loss is calculated: 5.960464477539063e-08\n",
      "tensor([[-0.0008, -0.1224,  0.3579]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0008, -0.1224,  0.3579]], device='cuda:0')\n",
      "tensor([[-0.0498,  0.7491, -0.6194,  0.2295]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[-0.0498,  0.7491, -0.6194,  0.2295]], device='cuda:0')\n",
      "Loss is calculated: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emircan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\core\\_methods.py:118: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\emircan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_numdiff.py:590: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_12312\\2088303396.py:107: RuntimeWarning: overflow encountered in multiply\n",
      "  rho = term1 * term2  # [H*W]\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_12312\\2088303396.py:112: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -0.5 * rho * (1.0 + erf(rho / np.sqrt(2.0)))  # GELU approximation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0185, -0.1276,  0.2581]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.8522e-02, -1.2763e-01,  8.9019e+09]], device='cuda:0')\n",
      "tensor([[-0.0273,  0.2933, -0.8849,  0.3609]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.8118,  0.3629, -0.3730,  0.2651]], device='cuda:0')\n",
      "Loss is calculated: 2.641442765215577e+19\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m init_pose \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([t_pred_no_grad, r_pred], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Forward pass through DiffPoseNet\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m refined_pose \u001b[38;5;241m=\u001b[39m \u001b[43mcheirality_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_flow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_pose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Calculate loss between refined pose and ground truth\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Assuming refined_pose contains both translation and rotation\u001b[39;00m\n\u001b[0;32m     63\u001b[0m t_pred_no_grad \u001b[38;5;241m=\u001b[39m refined_pose[:, :\u001b[38;5;241m3\u001b[39m]  \u001b[38;5;66;03m# Predicted translation\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m, in \u001b[0;36mCheiralityLayer.forward\u001b[1;34m(self, normal_flow, image_gradients, init_pose)\u001b[0m\n\u001b[0;32m     37\u001b[0m     init_p \u001b[38;5;241m=\u001b[39m init_pose[i]  \u001b[38;5;66;03m# [6]\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Convert to numpy for L-BFGS (paper uses this approach)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Note: In practice you might want to keep everything in PyTorch\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     refined_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_pose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     refined_poses\u001b[38;5;241m.\u001b[39mappend(refined_p)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(refined_poses, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 116\u001b[0m, in \u001b[0;36mCheiralityLayer.optimize_pose\u001b[1;34m(self, normal_flow, image_gradients, init_pose)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(loss)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Run L-BFGS optimization\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m                 \u001b[49m\u001b[43minit_pose_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m refined_pose \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(result\u001b[38;5;241m.\u001b[39mx)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(init_pose\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m refined_pose\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:297\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[1;32m--> 267\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:181\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_numdiff.py:519\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    516\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_numdiff.py:590\u001b[0m, in \u001b[0;36m_dense_difference\u001b[1;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[0;32m    588\u001b[0m     x \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[0;32m    589\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[0;32m    592\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_numdiff.py:470\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(x\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    468\u001b[0m     x \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(x, x0\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 470\u001b[0m f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    473\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[1;32mIn[4], line 103\u001b[0m, in \u001b[0;36mCheiralityLayer.optimize_pose.<locals>.objective\u001b[1;34m(pose_params)\u001b[0m\n\u001b[0;32m     96\u001b[0m B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\n\u001b[0;32m     97\u001b[0m     x\u001b[38;5;241m*\u001b[39my, \u001b[38;5;241m-\u001b[39m(x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), y,\n\u001b[0;32m     98\u001b[0m     (y\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m-\u001b[39mx\u001b[38;5;241m*\u001b[39my, \u001b[38;5;241m-\u001b[39mx\n\u001b[0;32m     99\u001b[0m ], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    102\u001b[0m g_dot_A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(grad_dir_np\u001b[38;5;241m.\u001b[39mT[:, np\u001b[38;5;241m.\u001b[39mnewaxis, :], A)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [H*W, 3]\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m g_dot_B \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_dir_np\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    104\u001b[0m term1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(g_dot_A, V)  \u001b[38;5;66;03m# [H*W]\u001b[39;00m\n\u001b[0;32m    105\u001b[0m term2 \u001b[38;5;241m=\u001b[39m nf_np \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(g_dot_B, Omega)  \u001b[38;5;66;03m# [H*W]\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nflownet.eval()  # We won't train the flow networks\n",
    "pose_net.train()  # Only train PoseNet\n",
    "cheirality_layer = CheiralityLayer().to(device)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = TartanAirDataset(root_dir=\"D:/KOC UNIVERSITY/COMP447/data/image_left\")\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Optimizer (only for PoseNet parameters)\n",
    "optimizer = optim.Adam(pose_net.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (images, translations, rotations) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        translations = translations.to(device)\n",
    "        rotations = rotations.to(device)\n",
    "        pose_net.train()\n",
    "        nflownet.eval() \n",
    "        # Split images into pairs (assuming consecutive frames)\n",
    "        img1 = images[:, 0]  # First image in pair\n",
    "        img2 = images[:, 1]  # Second image in pair\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t_pred, q_pred = pose_net(torch.stack([img1, img2], dim=1))\n",
    "\n",
    "        t_pred_no_grad = t_pred\n",
    "        q_pred_no_grad =q_pred\n",
    "        # Compute normal flow between images\n",
    "        with torch.no_grad():\n",
    "            resize_transform = transforms.Compose([\n",
    "            transforms.Resize((480, 640))  # (height, width)\n",
    "            ])\n",
    "            img1_resized = resize_transform(img1)\n",
    "            img2_resized = resize_transform(img2)\n",
    "            img = torch.cat((img1_resized, img2_resized), dim=1)\n",
    "            normal_flow = nflownet(img)  # [B, H, W]\n",
    "        \n",
    "            # Compute image gradients (for cheirality layer)\n",
    "            # Using Sobel filters as approximation\n",
    "            sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32, device=img1.device).view(1, 1, 3, 3)\n",
    "            sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32, device=img1.device).view(1, 1, 3, 3)\n",
    "            \n",
    "            # Compute gradients for both images and average\n",
    "            grad_x1 = F.conv2d(img1_resized.mean(dim=1, keepdim=True), sobel_x, padding=1)\n",
    "            grad_y1 = F.conv2d(img1_resized.mean(dim=1, keepdim=True), sobel_y, padding=1)\n",
    "            grad_x2 = F.conv2d(img2_resized.mean(dim=1, keepdim=True), sobel_x, padding=1)\n",
    "            grad_y2 = F.conv2d(img2_resized.mean(dim=1, keepdim=True), sobel_y, padding=1)\n",
    "            \n",
    "            image_gradients = 0.5 * (torch.cat([grad_x1, grad_y1], dim=1) + torch.cat([grad_x2, grad_y2], dim=1))  # [B, 2, H, W]\n",
    "            \n",
    "            r_pred = quaternion_to_euler_xyz(q_pred_no_grad)\n",
    "            init_pose = torch.cat([t_pred_no_grad, r_pred], dim=1) \n",
    "        \n",
    "            # Forward pass through DiffPoseNet\n",
    "            refined_pose = cheirality_layer(normal_flow, image_gradients, init_pose)\n",
    "            # Calculate loss between refined pose and ground truth\n",
    "            # Assuming refined_pose contains both translation and rotation\n",
    "            t_pred_no_grad = refined_pose[:, :3]  # Predicted translation\n",
    "            euler_angles = refined_pose[:, 3:]  # [B, 3] -> [roll, pitch, yaw]\n",
    "            q_pred_no_grad = euler_xyz_to_quaternion(euler_angles)\n",
    "        # Use PoseNet's loss function\n",
    "        loss = pose_net.pose_loss(t_pred, q_pred, t_pred_no_grad, q_pred_no_grad)\n",
    "        print(f\"Loss is calculated: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}: Loss = {loss.item():.6f}\")\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch} completed. Average Loss: {avg_loss:.6f}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
