{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from posenet.model import PoseNetDino\n",
    "from nflownet.model import NFlowNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from dataset.tartanair import TartanAirDataset\n",
    "import random\n",
    "import numpy as np\n",
    "# from cheirality.cheiralityLayer import CheiralityLayer\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = TartanAirDataset(root_dir=\"D:/KOC UNIVERSITY/COMP447/data/image_left\")\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "def load_posenet(posenet_path):\n",
    "    # Initialize PoseNet model\n",
    "    posenet = PoseNetDino().to(device)\n",
    "    \n",
    "    # Load weights from .safetensors file\n",
    "    with safe_open(posenet_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        state_dict = {}\n",
    "        for key in f.keys():\n",
    "            state_dict[key] = f.get_tensor(key)\n",
    "    \n",
    "    # Load state dict into model\n",
    "    posenet.load_state_dict(state_dict)\n",
    "    posenet.train()\n",
    "    \n",
    "    return posenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nflownet(nflownet_path):\n",
    "    # Initialize FlowNet model\n",
    "    nflownet = NFlowNet().to(device)\n",
    "    \n",
    "    # Load weights from .pth file\n",
    "    checkpoint = torch.load(nflownet_path, map_location=device)\n",
    "    \n",
    "    # Handle different save formats\n",
    "    if 'state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    elif 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    # Load state dict into model\n",
    "    nflownet.load_state_dict(state_dict)\n",
    "    nflownet.eval()  # Set to evaluation mode\n",
    "    \n",
    "    return nflownet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\emircan/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "C:\\Users\\emircan/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "C:\\Users\\emircan/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "C:\\Users\\emircan/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "C:\\Users\\emircan\\AppData\\Local\\Temp\\ipykernel_7912\\1393321933.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(nflownet_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "posenet_path = r\"D:\\KOC UNIVERSITY\\COMP447\\trainedmodels\\posenet\\model.safetensors\"\n",
    "nflownet_path = r\"D:\\KOC UNIVERSITY\\COMP447\\trainedmodels\\nflownet\\nflownet_final.pth\"\n",
    "\n",
    " #posenet = load_posenet(posenet_path\n",
    " \n",
    "posenet = PoseNetDino().to(device)\n",
    "nflownet = load_nflownet(nflownet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from nflownet.utils import compute_image_gradients\n",
    "import kornia\n",
    "import kornia_rs\n",
    "\n",
    "class CheiralityLayer(nn.Module):\n",
    "    def __init__(self, posenet, nflownet):\n",
    "        super().__init__()\n",
    "        self.posenet = posenet\n",
    "        self.nflownet = nflownet\n",
    "        self.nflownet.eval()  # freeze NFlowNet\n",
    "        for p in self.nflownet.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def construct_A_B(self, H, W, device):\n",
    "        y, x = torch.meshgrid(torch.arange(H), torch.arange(W), indexing='ij')\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "\n",
    "        # A and B: [H, W, 2, 3]\n",
    "        A = torch.stack([\n",
    "            -torch.ones_like(x), torch.zeros_like(x), x,\n",
    "            torch.zeros_like(y), -torch.ones_like(y), y\n",
    "        ], dim=-1).reshape(H, W, 2, 3)\n",
    "\n",
    "        B = torch.stack([\n",
    "            x * y, -(x ** 2 + 1), y,\n",
    "            y ** 2 + 1, -x * y, -x\n",
    "        ], dim=-1).reshape(H, W, 2, 3)\n",
    "\n",
    "        # Reshape to [H*W, 2, 3]\n",
    "        A = A.view(-1, 2, 3)\n",
    "        B = B.view(-1, 2, 3)\n",
    "\n",
    "        return A, B\n",
    "\n",
    "    def cheirality_loss(self, img_pair_shape, pose, grad_dirs, normal_flow, device):\n",
    "        B, _, H, W = img_pair_shape\n",
    "        V, W_ = pose[:, :, :3], pose[:, :, 3:]  # [B, 1, 3]\n",
    "\n",
    "        A, B_mat = self.construct_A_B(H, W, device)  # [H*W, 2, 3]\n",
    "\n",
    "        # Gradient directions\n",
    "        grad_x, grad_y = grad_dirs  # each: [B, H, W]\n",
    "        gx = torch.stack([grad_x, grad_y], dim=-1).view(B, H*W, 2)  # [B, H*W, 2]\n",
    "        gx_unit = F.normalize(gx, dim=-1)  # [B, H*W, 2]\n",
    "\n",
    "        # Normal flow: [B, 2, H, W] -> [B, H*W, 2]\n",
    "        nf = normal_flow.permute(0, 2, 3, 1).view(B, H*W, 2)\n",
    "\n",
    "        # Compute scalar projection of normal flow onto gradient direction\n",
    "        nf_scalar = torch.sum(nf * gx_unit, dim=-1)  # [B, H*W]\n",
    "\n",
    "        # gA = gx · A → [B, H*W, 3]\n",
    "        gA = torch.einsum('bpi,pij->bpj', gx_unit, A)\n",
    "\n",
    "        # gB = gx · B → [B, H*W, 3]\n",
    "        gB = torch.einsum('bpi,pij->bpj', gx_unit, B_mat)\n",
    "\n",
    "        # term1 = gA @ V → [B, H*W]\n",
    "        term1 = torch.sum(gA * V, dim=-1)\n",
    "\n",
    "        # term2 = nf_scalar - (gB @ Omega) → [B, H*W]\n",
    "        term2 = nf_scalar - torch.sum(gB * W_, dim=-1)\n",
    "\n",
    "        # rho = term1 * term2\n",
    "        rho = term1 * term2  # [B, H*W]\n",
    "\n",
    "        # Penalize negative values of rho\n",
    "        loss = F.gelu(-rho).mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    def refine_pose(self, img_pair_shape, Pec, grad_dirs, normal_flow):\n",
    "        B = Pec.shape[0]\n",
    "        Per = Pec.clone().detach().requires_grad_(True)\n",
    "\n",
    "        optimizer = torch.optim.LBFGS([Per], max_iter=300, line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.cheirality_loss(img_pair_shape, Per, grad_dirs, normal_flow, Pec.device)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        # Cheirality loss after refinement\n",
    "        loss_cheirality = self.cheirality_loss(img_pair_shape, Per, grad_dirs, normal_flow, Pec.device)\n",
    "\n",
    "        # Compute dL/dPer (gradient of cheirality loss wrt Per)\n",
    "        grad_cheirality = grad(loss_cheirality, Per, create_graph=True)[0]  # shape: [B, 6]\n",
    "\n",
    "        return Per, grad_cheirality\n",
    "\n",
    "    #torch autograd.grad\n",
    "\n",
    "    def upper_level_loss(self, img_pair_shape, Pec, Per, n_flow_pred, grad_dirs, device):\n",
    "        B, _, H, W = img_pair_shape\n",
    "        A, B_mat = self.construct_A_B(H, W, device)  # [H*W, 2, 3]\n",
    "\n",
    "        grad_x, grad_y = grad_dirs  # each [B, H, W]\n",
    "\n",
    "        # Stack and reshape gradient directions: [B, H, W, 2] -> [B, H*W, 2]\n",
    "        g_x = torch.stack([grad_x, grad_y], dim=-1).view(B, H*W, 2)\n",
    "        gx_unit = F.normalize(g_x, dim=-1)  # normalize gradient directions\n",
    "\n",
    "        # Reshape predicted normal flow vector to [B, H*W, 2]\n",
    "        n_flow_vec = n_flow_pred.permute(0, 2, 3, 1).reshape(B, H*W, 2)  # [B, H*W, 2]\n",
    "\n",
    "        # Project predicted normal flow vector along gradient directions (scalar)\n",
    "        n_flow_scalar = torch.sum(n_flow_vec * gx_unit, dim=-1)  # [B, H*W]\n",
    "\n",
    "        # Pose splits (translation and rotation)\n",
    "        V_r, Omega_r = Per[:,:, :3], Per[:,:, 3:]  # [B, 3]\n",
    "        V_c, Omega_c = Pec[:,:, :3], Pec[:,:, 3:]  # [B, 3]\n",
    "\n",
    "        # Project A and B matrices along gradient directions\n",
    "        g_dot_A = torch.einsum(\"bpi,pij->bpj\", gx_unit, A)      # [B, H*W, 3]\n",
    "        g_dot_B = torch.einsum(\"bpi,pij->bpj\", gx_unit, B_mat)  # [B, H*W, 3]\n",
    "\n",
    "        # Compute derotation term: (gx · B) · Omega_r\n",
    "        g_dot_B_Omega_r = torch.sum(g_dot_B * Omega_r.unsqueeze(1), dim=-1)  # [B, H*W]\n",
    "\n",
    "        # Compute translational term: (gx · A) · V_r\n",
    "        g_dot_A_V_r = torch.sum(g_dot_A * V_r.unsqueeze(1), dim=-1)  # [B, H*W]\n",
    "\n",
    "        # Compute denominator of depth scale: n_x - (gx · B) · Omega_r\n",
    "        denom = n_flow_scalar - g_dot_B_Omega_r  # [B, H*W]\n",
    "        eps = 1e-6\n",
    "        depth_scale = g_dot_A_V_r / (denom + eps)  # [B, H*W]\n",
    "\n",
    "        # Compute terms for coarse pose Pec\n",
    "        g_dot_A_V_c = torch.sum(g_dot_A * V_c.unsqueeze(1), dim=-1)  # [B, H*W]\n",
    "        g_dot_B_Omega_c = torch.sum(g_dot_B * Omega_c.unsqueeze(1), dim=-1)  # [B, H*W]\n",
    "\n",
    "        # Predict normal flow scalar from coarse pose Pec using depth scale\n",
    "        n_flow_pred_from_pose = (g_dot_A_V_c / (depth_scale + eps)) - g_dot_B_Omega_c  # [B, H*W]\n",
    "\n",
    "        # Compute MSE loss between predicted scalar normal flow and model predicted scalar normal flow\n",
    "        n_flow_pred_from_pose = n_flow_pred_from_pose.squeeze(1)  # now shape [1, 307200]\n",
    "\n",
    "        loss = F.mse_loss(n_flow_pred_from_pose, n_flow_scalar)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def forward(self, img_pair):\n",
    "\n",
    "        # Coarse pose from PoseNet\n",
    "        translation, rotation = self.posenet(img_pair)\n",
    "        q_flat = rotation.reshape(-1, 4)\n",
    "        # Convert to rotation vector (axis-angle): [B * T, 3]\n",
    "        rotvec_flat = kornia.geometry.quaternion_to_axis_angle(q_flat)\n",
    "\n",
    "        # Geri reshape: [B, T, 3]\n",
    "        rotation = rotvec_flat.view(rotation.shape[0], rotation.shape[1], 3)\n",
    "        Pec = torch.cat([translation, rotation], dim=-1) \n",
    "        \n",
    "        img_pair = img_pair.view(1, 2 * 3, 224, 224)\n",
    "        img_pair = F.interpolate(img_pair, size=(480, 640), mode='bilinear', align_corners=False)\n",
    "\n",
    "        nflow_pred = self.nflownet(img_pair)\n",
    "        gray = img_pair[:, :3].mean(1, keepdim=True)\n",
    "        grad_dirs = compute_image_gradients(gray)  # [B, 2, H, W]\n",
    "        img_pair_shape = img_pair.shape\n",
    "        # Lower-level: refine using cheirality\n",
    "        Per, dL_dPer = self.refine_pose(img_pair_shape, Pec, grad_dirs, nflow_pred)\n",
    "        \n",
    "        upper_loss = self.upper_level_loss(img_pair_shape, Pec, Per, nflow_pred, grad_dirs,img_pair.device)\n",
    "        \n",
    "        # ∂L_upper / ∂Pec + ∂L_upper / ∂Per * ∂Per / ∂Pec\n",
    "        dL_dPec_upper = grad(upper_loss, Pec, retain_graph=True, create_graph=True)[0]\n",
    "        dL_dPer_upper = grad(upper_loss, Per, retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "        # ∂L_total / ∂Pec = ∂L_upper / ∂Pec - dL_dPer_upper ⊙ d_cheirality_loss / d_Per\n",
    "        total_grad = dL_dPec_upper - torch.autograd.grad((dL_dPer * dL_dPer_upper).sum(), Pec, retain_graph=True)[0]\n",
    "\n",
    "\n",
    "        # Kayıp gibi davranarak backward yap\n",
    "        dummy_loss = (Pec * total_grad.detach()).sum()\n",
    "        return dummy_loss\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheirality_layer = CheiralityLayer(nflownet=nflownet,posenet=posenet).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.393683739374606e+21\n",
      "74665476096.0\n",
      "5.493046775904357e+28\n",
      "9.78152115307331e+21\n",
      "108484083712.0\n",
      "1185056236240896.0\n",
      "-2.793943361555568e+29\n",
      "-5.730164133821594e+20\n",
      "1.5564974674843533e+19\n",
      "-5.579944085641356e+25\n",
      "3.73453715934676e+20\n",
      "2.3890790301079647e+20\n",
      "202672832512.0\n",
      "73963454464.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[195], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, _, _ \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     10\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcheirality_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     13\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[193], line 172\u001b[0m, in \u001b[0;36mCheiralityLayer.forward\u001b[1;34m(self, img_pair)\u001b[0m\n\u001b[0;32m    170\u001b[0m img_pair_shape \u001b[38;5;241m=\u001b[39m img_pair\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Lower-level: refine using cheirality\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m Per, dL_dPer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefine_pose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_pair_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_dirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnflow_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m upper_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupper_level_loss(img_pair_shape, Pec, Per, nflow_pred, grad_dirs,img_pair\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# ∂L_upper / ∂Pec + ∂L_upper / ∂Per * ∂Per / ∂Pec\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[193], line 91\u001b[0m, in \u001b[0;36mCheiralityLayer.refine_pose\u001b[1;34m(self, img_pair_shape, Pec, grad_dirs, normal_flow)\u001b[0m\n\u001b[0;32m     88\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m---> 91\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Cheirality loss after refinement\u001b[39;00m\n\u001b[0;32m     94\u001b[0m loss_cheirality \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheirality_loss(img_pair_shape, Per, grad_dirs, normal_flow, Pec\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\lbfgs.py:444\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[1;32m--> 444\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[43m_strong_wolfe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtd\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m    448\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\lbfgs.py:48\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[1;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[0;32m     46\u001b[0m g \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# evaluate objective and gradient using initial step\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     50\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\lbfgs.py:442\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[1;34m(x, t, d)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directional_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\lbfgs.py:297\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[1;34m(self, closure, x, t, d)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m    296\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(closure())\n\u001b[1;32m--> 297\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather_flat_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_param(x)\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, flat_grad\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\lbfgs.py:270\u001b[0m, in \u001b[0;36mLBFGS._gather_flat_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    268\u001b[0m     view \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mto_dense()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m     view \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(view):\n\u001b[0;32m    272\u001b[0m     view \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(view)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Optimizer (only for PoseNet parameters)\n",
    "optimizer = optim.Adam(posenet.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for images, _, _ in train_loader:\n",
    "        images = images.to(device)\n",
    "        loss = cheirality_layer(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        print(loss.item())\n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss / len(train_loader)}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
